---
title: Audio
header:
  image: "/assets/images/title/header.png"
  caption: 'Image: [**Environmental Informatics Marburg**](https://www.uni-marburg.de/en/fb19/disciplines/physisch/environmentalinformatics)'
---

<!--more-->

# A theory of sound
Acoustic sensors, such as microphones or hydrophones, record sounds produced by animals, including vocalizations, mating calls, and other bioacoustic signals.
Basically, what a microphone does is convert sound into a small electrical current through a diaphragm that vibrates when it's hit by the sound wave.  This movement then affects a magnet near a coil, or vice versa, creating the electrical current. Carl R. Nave has a wonderful technical drawings which explain it in detail, [here] (http://hyperphysics.phy-astr.gsu.edu/hbase/Audio/mic.html).


The sound waves travel through a medium, typically air, but they can also propagate through liquids and solids. They are created by the vibration of an object, such as vocal cords which causes the particles in the surrounding medium to oscillate and transmit the energy of the vibration. The important characteristics of a sound wave are frequency, amplitude and wavelength.
Frequency refers to the number of one complete waves (with one negative and one positive alternation) that occur per unit of time and is measured in Hertz (Hz). Frequency determines the pitch of the sound, with higher frequencies corresponding to higher pitches and lower frequencies corresponding to lower pitches. Amplitude refers to the magnitude or intensity of the sound wave, which corresponds to its loudness or volume. It is measured in decibels (dB). Higher amplitudes produce louder sounds, while lower amplitudes produce softer sounds. Wavelength is the distance between successive points of the same phase in a wave, such as from one peak to the next peak or from one trough to the next trough. It is inversely proportional to frequency, meaning higher frequency waves (=higher pitches) have shorter wavelengths and vice versa.

Animal vocalizations typically exhibit distinctive spectral characteristics, where these three characteristics are moduled. For example, a bird might start its song with low-frequency notes,  gradually increasing the amplitude. As the song progresses, the bird may transition to higher frequencies and full amplitude. Analyzing these spectral features can help differentiate between different species or even in some instances individual animals. 

Once recordings are made, researchers analyze the audio data using specialized software capable of detecting and classifying sounds of interest. This process often involves the use of machine learning algorithms trained to recognize specific animal vocalizations based on their acoustic features.

Have a look at this brilliant video by Alison Styring, which exmplains the aforementioned principles:
[![](https://markdown-videos-api.jorgenkh.no/youtube/cvua_hycOUA)](https://youtu.be/cvua_hycOUA)
https://www.youtube.com/watch?v=cvua_hycOUA

There are two ways in which one can graphically represent sound. An oscillogram, also known as a waveform or time-domain plot, displays the amplitude of a sound signal over time.  Oscillograms provide a visual representation of the temporal characteristics of a sound signal. They are useful for analyzing features such as the duration of sounds, temporal patterns, and the presence of individual sound events within the signal. An audiospectrogram, also known as a spectrogram or frequency-domain plot, provides a more detailed analysis of the frequency content of a sound signal over time. Audiospectrograms are valuable for analyzing the spectral characteristics of sound signals, including the distribution of energy across different frequency bands, the presence of harmonics or overtones, and the occurrence of frequency modulations or shifts


# Autonomous sound recording
Autonomous Recording Units (ARUs) are typically equipped with microphones capable of capturing sounds within a specific frequency range. These microphones can vary depending on the application, with omnidirectional or directional microphones being commonly used.



## QUESTIONS TO DISCUSS ##
> What information can be gained by ARUs? 
> Waht advantaguos and disadvantagous are there in comparison to human listeners?


<details><summary>SPOILER</summary>
<p>

Human point counts include visual detections, which are beneficial but often under-reported in studies comparing point counts with ARUs. On the other hand, humans may introduce an avoidance effect that affects bird detections, especially when multiple observers are present. In addition, humans may miss some birds, especially during dawn chorus or due to human error, whereas recordings can be replayed, re-analysed and have the advantage of being verifiable by other people [^1]. - A qualitative call recording is stronger evidence than someone claiming to have heard a particular species. 


</p>
</details>
<!-- more to be added>

[1] https://esajournals.onlinelibrary.wiley.com/doi/10.1002/eap.1954